
# ğŸ¤– Agentic RAG System with ReAct Agent

**A Retrieval-Augmented Generation (RAG) system using a ReAct agent for interactive document Q&A.**  
Process PDFs, TXT files, and URLs, retrieve relevant content, and generate precise answers with references in a Streamlit UI.

---

## ğŸ¬ Demo
*Ask questions directly on your documents and get instant answers!*
---

## ğŸŒŸ Features

* Load documents from **PDFs, TXT files, and URLs**  
* Automatically **split documents** into RAG-friendly chunks  
* **Semantic search** with FAISS embeddings  
* **ReAct agent** for reasoning + tool usage (retriever + Wikipedia)  
* **Interactive Streamlit UI** for live Q&A  
* Maintain **query history** in session state  

---

## âš¡ Quick Start

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/TalhaShahzad-321/agentic-rag.git
cd Agentic-RAG-System
````

### 2ï¸âƒ£ Setup Environment

```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3ï¸âƒ£ Add Documents

* Place PDFs or TXT files in the `data/` folder.
* Optionally, add URLs in `data/urls.txt` (one URL per line).

### 4ï¸âƒ£ Run Streamlit UI

```bash
streamlit run streamlit_app.py
```

### 5ï¸âƒ£ Ask Questions

* Example:

```
summarize the "Attention Is All You Need" paper in 5 lines
```

### 6ï¸âƒ£ Run Command-Line Mode (Optional)

```bash
python main.py
```

---

## ğŸ“ Project Structure

```
Agentic-RAG-System/
â”‚
â”œâ”€ data/                      # PDFs, TXT files, URLs
â”œâ”€ src/
â”‚   â”œâ”€ config/                # LLM config, chunk size, default URLs
â”‚   â”œâ”€ document_ingestion/    # DocumentProcessor class
â”‚   â”œâ”€ vectorstore/           # VectorStore (FAISS) & retriever
â”‚   â”œâ”€ graph_builder/         # RAG graph & agent orchestration
â”‚   â””â”€ node/                  # Nodes (ReAct agent)
â”œâ”€ streamlit_app.py           # Streamlit UI frontend
â”œâ”€ main.py                    # Interactive CLI entry point
â”œâ”€ requirements.txt           # Dependencies
â””â”€ README.md                  # Project documentation
```

---

## ğŸ›  How It Works

1. **Load Documents** â†’ PDFs, TXT, URLs
2. **Chunk & Vectorize** â†’ Split into smaller pieces & create embeddings
3. **Retrieve Relevant Chunks** â†’ Using semantic search
4. **ReAct Agent** â†’ Combines retrieved docs + external tools to reason and generate answers
5. **Deliver Answer** â†’ Display answer with references

---

## ğŸ”® Future Enhancements

* Multi-language support for documents & external tools
* Integrate more sources (arXiv, GitHub, Wikipedia, etc.)
* Scalable vector store (Pinecone, Weaviate, etc.)
* Improved ReAct agent prompting and reasoning strategies

---

## ğŸ“š References

* [LangChain Documentation](https://www.langchain.com/docs/)
* [LangGraph Docs](https://docs.langgraph.com/)
* [FAISS: Efficient Similarity Search](https://faiss.ai/)
* Vaswani et al., â€œAttention Is All You Needâ€, 2017

---

## ğŸ“ License

MIT License Â© [Talha Shahzad]
